{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Constants\n",
    "DELAY = 50\n",
    "INPUT_TYPES = ['palm', 'fist', 'thumbsup', 'gun', 'call']\n",
    "MIN_INPUT_COUNT = 2000 + DELAY\n",
    "INPUT_PATH = 'Inputs/'\n",
    "\n",
    "# Make directories\n",
    "def make_dirs():\n",
    "    if not os.path.isdir(INPUT_PATH):\n",
    "        os.mkdir(INPUT_PATH, mode=511)\n",
    "    os.chdir(INPUT_PATH)\n",
    "    for dirs in INPUT_TYPES:\n",
    "        if not os.path.isdir(dirs):\n",
    "            os.mkdir(dirs, mode=511)\n",
    "    os.chdir('..')\n",
    "\n",
    "# Load data\n",
    "def load_data():\n",
    "    data = []\n",
    "    for types in INPUT_TYPES:\n",
    "        temp = INPUT_PATH + types + '/'\n",
    "        l = []\n",
    "        for file in os.listdir(temp):\n",
    "            if file.endswith('.jpg'):\n",
    "                image_matrix = plt.imread(temp + file)\n",
    "                l.append(image_matrix)\n",
    "        data.append(l)\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(data):\n",
    "    X, Y = [], []\n",
    "    i = 0\n",
    "    for class_ in data:\n",
    "        for image in class_:\n",
    "            X.append(image)\n",
    "            Y.append(i)\n",
    "        i += 1\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    X = X / 255.0\n",
    "    return X, Y\n",
    "\n",
    "# Train CNN model\n",
    "def train_model(X_train, Y_train):\n",
    "    cnn = models.Sequential([\n",
    "        layers.Conv2D(input_shape = X_train.shape[1:], filters = 32, kernel_size = (3,3), strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size = (2, 2), strides = (2,2), padding = 'same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size = (2, 2), strides = (2,2), padding = 'same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units = 512, activation = 'relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(units = len(INPUT_TYPES), activation = 'softmax')\n",
    "    ])\n",
    "    cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    start_time = time.time()\n",
    "    cnn.fit(X_train, Y_train, epochs=10)\n",
    "    end_time = time.time()\n",
    "    print(\"total time in seconds\", (end_time - start_time))\n",
    "    return cnn\n",
    "\n",
    "# Predict function\n",
    "def predict(cnn, img):\n",
    "    class_ = np.argmax(cnn.predict(img))\n",
    "    return INPUT_TYPES[class_]\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "# Capture from webcam\n",
    "webcam = 0\n",
    "capture = cv.VideoCapture(webcam)\n",
    "fps = int(capture.get(cv.CAP_PROP_FPS))\n",
    "print(\"fps is \" + str(fps))\n",
    "_, frame = capture.read()\n",
    "height, width, _ = frame.shape\n",
    "\n",
    "# Real-time prediction\n",
    "while capture.isOpened():\n",
    "    if cv.waitKey(1) & 0xFF == 13:\n",
    "        break\n",
    "    black = np.zeros(shape=frame.shape)\n",
    "    _, frame = capture.read()\n",
    "    frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    result = holistic.process(frame_rgb)\n",
    "    try:\n",
    "        hand_landmarks = result.right_hand_landmarks.landmark\n",
    "        if hand_landmarks:\n",
    "            x_max, y_max = 0, 0\n",
    "            x_min, y_min = width, height\n",
    "            for lm in hand_landmarks:\n",
    "                x, y = int(lm.x * width), int(lm.y * height)\n",
    "                x_max, y_max = max(x, x_max), max(y, y_max)\n",
    "                x_min, y_min = min(x, x_min), min(y, y_min)\n",
    "            frame_bgr = cv.cvtColor(frame_rgb, cv.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(frame_bgr, result.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            cv.rectangle(frame_bgr, (x_min - 25, y_min - 25), (x_max + 25, y_max + 25), (0, 255, 0), 2)\n",
    "            result1 = frame_bgr\n",
    "            mp_drawing.draw_landmarks(black, result.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            cropped = black[y_min - 23: y_max + 23, x_min - 23: x_max + 23]\n",
    "            resized = cv.resize(cropped, (96, 96))\n",
    "            result2 = cv.flip(resized, 1)\n",
    "            img_mat = np.array([result2])\n",
    "            class_ = predict(cnn, img_mat)\n",
    "            cv.putText(result1, str(class_), (100, 100), cv.FONT_HERSHEY_PLAIN, 2, (255,0,0), 1)\n",
    "            cv.imshow(\"Frame2\", result2)\n",
    "    except:\n",
    "        result1 = frame\n",
    "        pass\n",
    "    mirror1 = cv.flip(result1, 1)\n",
    "    cv.imshow('frame1', mirror1)\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
